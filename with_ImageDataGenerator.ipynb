{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "print(os.listdir(\"../input/dataset-for-mask-detection\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=200\n",
    "IMAGE_HEIGHT=200\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with = os.listdir(\"../input/dataset-for-mask-detection/dataset/with_mask\")\n",
    "filenames_without = os.listdir(\"../input/dataset-for-mask-detection/dataset/without_mask\")\n",
    "filenames_list_with = []\n",
    "filenames_list_without = []\n",
    "categories_with = []\n",
    "categories_without = []\n",
    "for filename in filenames_with:\n",
    "    filenames_list_with.append(\"../input/dataset-for-mask-detection/dataset/with_mask/\" + filename)\n",
    "    categories_with.append(1)\n",
    "for filename in filenames_without:\n",
    "    filenames_list_without.append(\"../input/dataset-for-mask-detection/dataset/without_mask/\" + filename)\n",
    "    categories_without.append(0)\n",
    "    \n",
    "\n",
    "df_w = pd.DataFrame({\n",
    "    'image': filenames_list_with,\n",
    "    'category': categories_with\n",
    "})\n",
    "df_wo = pd.DataFrame({\n",
    "    'image': filenames_list_without,\n",
    "    'category': categories_without\n",
    "})\n",
    "print(df_w.shape, df_wo.shape)\n",
    "df = df_w.append(df_wo)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Activation, BatchNormalization, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', strides=(2,2), input_shape=(IMAGE_WIDTH,IMAGE_HEIGHT,IMAGE_CHANNELS)))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = create_model()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0: 'unmasked', 1: 'masked'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=3, stratify = df['category'])\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "print(total_train)\n",
    "print(total_validate)\n",
    "train_df.to_csv('train_df.csv')\n",
    "validate_df.to_csv('validate_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_count')\n",
    "print(train_df['category'].value_counts())\n",
    "print('-----------------------------')\n",
    "print('validation_count')\n",
    "print(validate_df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "#     horizontal_flip=True,\n",
    "    zoom_range=0.4\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    x_col=\"image\",\n",
    "    y_col=\"category\",\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validate_filenames=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    x_col=\"image\",\n",
    "    y_col=\"category\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validate_filenames=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
    "example_generator = train_datagen.flow_from_dataframe(\n",
    "    example_df, \n",
    "    x_col='image',\n",
    "    y_col='category',\n",
    "    classes=['masked','unmasked'],\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    validate_filenames=False\n",
    ")\n",
    "print(example_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(0, 2):\n",
    "    plt.subplot(5, 3, i+1)\n",
    "    for X_batch, Y_batch in example_generator:\n",
    "        image = X_batch[0]\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//BATCH_SIZE,\n",
    "    steps_per_epoch=total_train//BATCH_SIZE,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, EPOCHS, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, EPOCHS, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
