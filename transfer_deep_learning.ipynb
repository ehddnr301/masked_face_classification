{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-65bc49e35e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=200\n",
    "IMAGE_HEIGHT=200\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with = os.listdir(\"../input/dataset-for-mask-detection/dataset/with_mask\")\n",
    "filenames_without = os.listdir(\"../input/dataset-for-mask-detection/dataset/without_mask\")\n",
    "filenames_list_with = []\n",
    "filenames_list_without = []\n",
    "categories_with = []\n",
    "categories_without = []\n",
    "for filename in filenames_with:\n",
    "    filenames_list_with.append(\"../input/dataset-for-mask-detection/dataset/with_mask/\" + filename)\n",
    "    categories_with.append(str(1))\n",
    "for filename in filenames_without:\n",
    "    filenames_list_without.append(\"../input/dataset-for-mask-detection/dataset/without_mask/\" + filename)\n",
    "    categories_without.append(str(0))\n",
    "    \n",
    "\n",
    "df_w = pd.DataFrame({\n",
    "    'image': filenames_list_with,\n",
    "    'category': categories_with\n",
    "})\n",
    "df_wo = pd.DataFrame({\n",
    "    'image': filenames_list_without,\n",
    "    'category': categories_without\n",
    "})\n",
    "print(df_w.shape, df_wo.shape)\n",
    "df = df_w.append(df_wo)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and valid set\n",
    "train_df, valid_df = train_test_split(df, test_size = 0.15, stratify = df['category'], random_state = 3)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "total_train = train_df.shape[0]\n",
    "total_valid = valid_df.shape[0]\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll perform individually on train and validation set.\n",
    "train_datagen = ImageDataGenerator(\n",
    "#                                    zoom_range = 0.2,\n",
    "                                   rescale=1./255,\n",
    "                                   horizontal_flip = True,\n",
    "                                   )\n",
    "#fill_mode : 이미지를 회전, 이동하거나 축소할 때 생기는 공간을 채우는 방식\n",
    "\n",
    "train_gen = train_datagen.flow_from_dataframe(train_df,\n",
    "                                              x_col = 'image',\n",
    "                                              y_col = 'category',\n",
    "                                              target_size = IMAGE_SIZE,\n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              class_mode='binary',\n",
    "                                              validate_filenames=False\n",
    "                                             )\n",
    "\n",
    "#we do not augment validation data.\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_gen = validation_datagen.flow_from_dataframe(\n",
    "    valid_df, \n",
    "    x_col=\"image\",\n",
    "    y_col=\"category\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validate_filenames=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(ResNet50(include_top = False, pooling = 'max', weights = 'imagenet'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.layers[0].trainable = False \n",
    "    model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'binary_crossentropy')    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "checkpointer = ModelCheckpoint(filepath = 'mask.weights.best.hdf5', save_best_only = True, save_weights_only = True)\n",
    "callbacks = [learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_data = valid_gen,\n",
    "                    validation_steps=total_valid//BATCH_SIZE,\n",
    "                    steps_per_epoch=total_train//BATCH_SIZE,\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss[['loss', 'val_loss']].plot()\n",
    "loss[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
