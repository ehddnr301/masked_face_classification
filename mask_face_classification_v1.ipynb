{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=150\n",
    "IMAGE_HEIGHT=150\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "with_mask = os.listdir(\"./dataset/with_mask\")\n",
    "without_mask = os.listdir(\"./dataset/without_mask\")\n",
    "\n",
    "def add_path1(filename):\n",
    "    return './dataset/with_mask/' + filename\n",
    "def add_path2(filename):\n",
    "    return './dataset/without_mask/' + filename\n",
    "\n",
    "w_mask = list(map(add_path1, with_mask))\n",
    "wo_mask = list(map(add_path2, without_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 preprocessing & label\n",
    "\n",
    "def dataset(file_list_with, file_list_without,size=(IMAGE_HEIGHT,IMAGE_WIDTH),flattened=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i, file in enumerate(file_list_with):\n",
    "        if(file ==\"./dataset/with_mask/.ipynb_checkpoints\"):\n",
    "            continue\n",
    "        image = io.imread(file)\n",
    "        image = transform.resize(image, size, mode='constant')\n",
    "        data.append(image)\n",
    "        labels.append(1)\n",
    "    for i, file in enumerate(file_list_without):\n",
    "        if(file ==\"./dataset/without_mask/.ipynb_checkpoints\"):\n",
    "            continue\n",
    "        image = io.imread(file)\n",
    "        image = transform.resize(image, size, mode='constant')\n",
    "        data.append(image)\n",
    "        labels.append(0)\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skimage 의 transform.resize 가 auto scale 되서 나오는듯합니다.\n",
    "# 0-1 의 범위를 가지고 있습니다.\n",
    "\n",
    "X, y = dataset(w_mask, wo_mask)\n",
    "print(X.shape,y.shape)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인하기\n",
    "sample_1 = random.choice(X)\n",
    "\n",
    "f = plt.figure()\n",
    "plt.imshow(sample_1)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', strides=(2,2), input_shape=(IMAGE_WIDTH,IMAGE_HEIGHT,IMAGE_CHANNELS)))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_x_train, validation_x_train, partial_y_train, validation_y_train = train_test_split(x_train, y_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(partial_x_train.shape,validation_x_train.shape,partial_y_train.shape,validation_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The size of the training set: ',len(x_train))\n",
    "print('The size of the partial training set: ',len(partial_x_train))\n",
    "print('The size of the validation training set: ',len(validation_x_train))\n",
    "print('The size of the testing set: ',len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit(\n",
    "    partial_x_train, \n",
    "    partial_y_train,\n",
    "    validation_data=(validation_x_train, validation_y_train),\n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8): #this function will make our plots more smooth\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous*factor+point*(1-factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(acc)+1)\n",
    "plt.plot(epochs, smooth_curve(acc), 'bo', label='Training acc')\n",
    "plt.plot(epochs, smooth_curve(val_acc), 'r-', label='Validation acc')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Acc')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, smooth_curve(loss), 'bo', label='Training loss')\n",
    "plt.plot(epochs, smooth_curve(val_loss), 'r-', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model1.evaluate(x_test, y_test)\n",
    "print('The final test accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
